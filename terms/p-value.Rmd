## p-value

<dfn>The probability of seeing an effect at least as extreme as what you have, if the real effect was the value you are testing against (e.g., a null effect)</dfn>

For example, if you used a binomial test to test against a chance probability of 1/2 (e.g., the probability of heads when flipping a fair coin), then a p-value of 0.37 means that you could expect to see effects at least as extreme as your data (i.e., 55 or more heads **or** tails) 37% of the time just by chance alone.

```{r}
# test how likely 55 heads (or a more extreme value)
# is to result from 100 flips of a fair (prob = 0.5) coin
binom.test(55, 100, 0.5)
```

P-values can be one-tailed or two-tailed. The example above if two-tailed because we didn't specify a direction and are testing whether there were more **or** fewer heads than expected by chance with a fair coin. The example below is one-tailed, and indicates that you have an 18% chance of getting 55 **or more** heads when flipping a fair coin 100 times.

```{r}
# test how likely 55 (or more) heads
# is to result from 100 flips of a fair (prob = 0.5) coin
binom.test(55, 100, 0.5, alternative = "greater")
```

You can see that the p-value is half of the two-tailed value; this is true for symmetric distributions like the [binomial distribution](b.html#binomial-distribution), but not for all distributions.

If you do a one-tailed test using "less", the p-value is much higher, indicating that you have an 86% chance of getting 55 **or fewer** heads when flipping a fair coin 100 times. 

```{r}
# test how likely 55 (or fewer) heads
# is to result from 100 flips of a fair (prob = 0.5) coin
binom.test(55, 100, 0.5, alternative = "less")
```